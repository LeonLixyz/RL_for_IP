{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TN-sMTvcG_9"
   },
   "source": [
    "## See README.md file for further details about the project and the environment.\n",
    "\n",
    "### State-Action Description\n",
    "\n",
    "### State\n",
    "State s is an array with give components\n",
    "\n",
    "* s[0]:  constraint matrix $A$of the current LP ($\\max  -c^Tx \\text{ s.t. }Ax \\le  b$) . Dimension is $m \\times n$. See by printing s[0].shape. Here $n$ is the (fixed) number of variables. For instances of size 60 by 60 used in the above command, $n$ will remain fixed as 60. And $m$ is the current number of constraints. Initially, $m$ is to the number of constraints in the IP instance. (For instances generated with --num-c=60, $m$ is 60 at the first step).  But $m$ will increase by one in every step of the episode as one new constraint (cut) is added on taking an action.\n",
    "* s[1]: rhs $b$ for the current LP ($Ax\\le b$). Dimension same as the number $m$ in matrix A.\n",
    "* s[2]: coefficient vector $c$ from the LP objective ($-c^Tx$). Dimension same as the number of variables, i.e., $n$.\n",
    "* s[3],  s[4]: Gomory cuts available in the current round of Gomory's cutting plane algorithm. Each cut $i$ is of the form $D_i x\\le d_i$.   s[3] gives the matrix $D$ (of dimension $k \\times n$) of cuts and s[4] gives the rhs $d$ (of dimension $k$). The number of cuts $k$ available in each round changes, you can find it out by printing the size of last component of state, i.e., s[4].size or s[-1].size.\n",
    "\n",
    "### Actions\n",
    "There are k=s[4].size actions available in each state $s$, with $i^{th}$ action corresponding to the $i^{th}$ cut with inequality $D_i x\\le d_i$ in $s[3], s[4]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xSXTKB2zurrt",
    "outputId": "0a8ed989-5fe1-48a5-f22e-1383ee8b7524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.gurobi.com\r\n",
      "Requirement already satisfied: gurobipy in /Users/leon66/miniforge3/lib/python3.10/site-packages (10.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -i https://pypi.gurobi.com gurobipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YULy9ymNvDxN",
    "outputId": "dc0eb470-f94d-46a2-d25f-ed6bfb08b621"
   },
   "outputs": [],
   "source": [
    "!pip install wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import policy_network as PN\n",
    "import helper as H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mleonli66\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymenv_v2\n",
    "from gymenv_v2 import make_multiple_env\n",
    "import numpy as np\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2xI0riE6md5V",
    "outputId": "0e4b479f-372f-46c2-dea6-4d1b2dd3e7c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:363jfrnz) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training reward</td><td>▆██▆█▁</td></tr><tr><td>training reward moving average</td><td>▁▁▁▁██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training reward</td><td>0.00029</td></tr><tr><td>training reward moving average</td><td>0.0563</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">efficient-aardvark-5215</strong>: <a href=\"https://wandb.ai/orcs4529/finalproject/runs/363jfrnz\" target=\"_blank\">https://wandb.ai/orcs4529/finalproject/runs/363jfrnz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221217_205144-363jfrnz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:363jfrnz). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b5660d410742d5b396b98a64899fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016752340266248212, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leon66/Desktop/Machine Learning/Reinforcement Learning/Final Project/al4263_LeonLi_Project/wandb/run-20221217_205231-104h5ukj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/orcs4529/finalproject/runs/104h5ukj\" target=\"_blank\">vivid-forest-5216</a></strong> to <a href=\"https://wandb.ai/orcs4529/finalproject\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training instances, dir instances/train_10_n60_m60 idx 0\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 1\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 2\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 3\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 4\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 5\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 6\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 7\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 8\n",
      "loading training instances, dir instances/train_10_n60_m60 idx 9\n",
      "0 :  0.9216160135863447 3.783835412850882\n",
      "1 :  0.7082653196353021 2.8696675312820448\n",
      "2 :  0.6072478073228922 2.468401910800032\n",
      "3 :  1.1013110904359564 27.475209237605\n",
      "4 :  0.7022608542010857 2.0944960128247048\n",
      "5 :  1.115349081867862 17.461775616708774\n",
      "6 :  0.7058461509368499 3.571921094096939e-11\n",
      "7 :  0.6151751669476653 8.879925617057352e-11\n",
      "8 :  0.8867413289876822 5.0551774244813614e-11\n",
      "9 :  1.115063939699212 0.6387979274283181\n",
      "10 :  0.7022608542010857 3.2535739655478675e-11\n",
      "11 :  0.6072478073228922 5.506437505157449e-11\n",
      "12 :  1.1013110904359564 0.33316941666975264\n",
      "13 :  0.7058461509368499 2.6337003202990476e-11\n",
      "14 :  0.8867413289876822 4.063349556064779e-11\n",
      "15 :  1.115063939699212 0.29095520145254355\n",
      "16 :  0.6151751669476653 5.8121654574865905e-11\n",
      "17 :  0.9216160135867995 4.07956979547361e-11\n",
      "18 :  0.7082653196353021 4.365318116737857e-11\n",
      "19 :  1.115349081867862 1.2716348284673855\n",
      "20 :  1.115349081867862 0.8096881114580798\n",
      "21 :  0.9216160135867995 2.0269124890633143e-11\n",
      "22 :  0.6072478073228922 2.920718023174948e-11\n",
      "23 :  0.7022608542010857 1.8382199186742358e-11\n",
      "24 :  0.8867413289876822 2.438528437327626e-11\n",
      "25 :  1.115063939699212 0.010262109246946352\n",
      "26 :  0.7082653196353021 3.22698417859992e-11\n",
      "27 :  0.7058461509368499 1.4976541124403592e-11\n",
      "28 :  1.1013110904359564 0.03467765363547736\n",
      "29 :  0.6151751669476653 3.619599176033879e-11\n"
     ]
    }
   ],
   "source": [
    "run=wandb.init(project=\"finalproject\", entity=\"orcs4529\", tags=[\"training-easy\"])\n",
    "#run=wandb.init(project=\"finalproject\", entity=\"orcs4529\", tags=[\"training-hard\"])\n",
    "#run=wandb.init(project=\"finalproject\", entity=\"orcs4529\", tags=[\"test\"])\n",
    "\n",
    "### TRAINING\n",
    "\n",
    "# Easy Setup: Use the following environment settings. We will evaluate your agent with the same easy config below:\n",
    "easy_config = {\n",
    "    \"load_dir\"        : 'instances/train_10_n60_m60',\n",
    "    \"idx_list\"        : list(range(10)),\n",
    "    \"timelimit\"       : 50,\n",
    "    \"reward_type\"     : 'obj'\n",
    "}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # create env\n",
    "    \n",
    "    var_size = 61\n",
    "    attention_size = 32\n",
    "    k = 16\n",
    "    hidden_size= 64\n",
    "    lr = 3e-4\n",
    "    Policy = PN.Policy_Network(var_size = var_size, attention_size = attention_size, k = k, hidden_size = hidden_size, lr = lr)\n",
    "    env = make_multiple_env(**easy_config)\n",
    "    sigma = 5\n",
    "    gamma = 0.99\n",
    "    rrecord = []\n",
    "\n",
    "    # To record traectories generated from current policy\n",
    "    \n",
    "    for e in range(30): \n",
    "\n",
    "        CONSTRAINTS = []  \n",
    "        CANDIDATES = []\n",
    "        ACTS = []\n",
    "        PROBABILITY = []  \n",
    "        REWARDS = []  \n",
    "\n",
    "        s = env.reset()   # samples a random instance every time env.reset() is called\n",
    "        d = False\n",
    "        t = 0\n",
    "        repisode = 0\n",
    "        total_loss = 0\n",
    "        \n",
    "        while not d:\n",
    "            #Take a random action\n",
    "            A, b, c0, cuts_a, cuts_b = s\n",
    "            # find attention score\n",
    "            a_b = np.concatenate((A,np.expand_dims(b,-1)),1)\n",
    "            d_e = np.concatenate((cuts_a,np.expand_dims(cuts_b,-1)),1)\n",
    "            total = np.concatenate((a_b, d_e),0)\n",
    "            \n",
    "            total = (total - np.mean(total)) / np.std(total)\n",
    "            #total / np.linalg.norm(total)\n",
    "            \n",
    "            constraint = total[:len(a_b)]\n",
    "            candidate = total[len(a_b):]\n",
    "\n",
    "            CONSTRAINTS.append(constraint)\n",
    "            CANDIDATES.append(candidate)\n",
    "            attention_score = Policy.compute_attention(constraint, candidate)\n",
    "            prob = Policy.compute_prob(attention_score)\n",
    "            \n",
    "            a = np.array([np.argmax(prob)])\n",
    "            ACTS.append(a)\n",
    "\n",
    "            s, r, d, _ = env.step(a)\n",
    "            #print('episode', e, 'step', t, 'reward', r)            \n",
    "            REWARDS.append(r)\n",
    "\n",
    "            t += 1\n",
    "            repisode += r\n",
    "            \n",
    "        \n",
    "        #Below is for logging training performance\n",
    "        rrecord.append(np.sum(REWARDS))\n",
    "        \n",
    "        # TODO:  Use discounted_rewards function to compute \\hat{V}s/\\hat{Q}s  from instant rewards in rews\n",
    "        discounted_r = H.discounted_rewards(REWARDS, gamma)\n",
    "        Q_s = H.evolution_strategies(discounted_r, sigma)\n",
    "        \n",
    "        for contraint,candidate,act,q_s in zip(CONSTRAINTS,CANDIDATES,ACTS,Q_s):\n",
    "            loss = Policy.train(contraint,candidate,act,np.array([q_s]))\n",
    "            total_loss += loss\n",
    "        print(e, \": \", repisode, total_loss)\n",
    "\n",
    "        fixedWindow=5\n",
    "        movingAverage=0\n",
    "        if len(rrecord) >= fixedWindow:\n",
    "            movingAverage=np.mean(rrecord[len(rrecord)-fixedWindow:len(rrecord)-1])\n",
    "\n",
    "        #wandb logging\n",
    "        wandb.log({ \"training reward\" : rrecord[-1], \"training reward moving average\" : movingAverage})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "PATH = cwd + '/Policy/easy_model'\n",
    "torch.save(Policy, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curriculum Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currect curriculum:  1\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 0\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 1\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 2\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 3\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 4\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 5\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 6\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 7\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 8\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 9\n",
      "0 :  0.6072478073228922 2.4941501629267506\n",
      "1 :  0.7022608541983573 2.8626708992901575\n",
      "2 :  0.6151751669476653 2.4876391899464974\n",
      "3 :  0.7082653196353021 2.8016526706404523\n",
      "4 :  0.9216160135867995 3.54339528182613\n",
      "5 :  1.115349081867862 24.645779786632524\n",
      "6 :  0.8867413289876822 3.3233959258353956e-11\n",
      "7 :  1.1013110904359564 0.43081368743287085\n",
      "8 :  0.7058461509368499 1.8961526513032532e-11\n",
      "9 :  1.1150639396978477 0.46922834640165584\n",
      "10 :  0.7082653196353021 3.165512752531424e-11\n",
      "11 :  0.7058461509368499 1.5900061567614665e-11\n",
      "12 :  1.1013110904359564 0.2736549750867936\n",
      "13 :  0.8867413289876822 2.4928515853744213e-11\n",
      "14 :  0.6072478073228922 2.9522510776725936e-11\n",
      "15 :  0.7022608542010857 1.892335736300916e-11\n",
      "16 :  0.6151751669476653 4.3752273696717884e-11\n",
      "17 :  0.9216160135867995 3.15545972824103e-11\n",
      "18 :  1.1150639396978477 0.2324827517501388\n",
      "19 :  1.115349081867862 0.7935458812613512\n",
      "20 :  0.7082653196353021 2.4105423488652277e-11\n",
      "21 :  1.1013110904359564 0.0878295289885673\n",
      "22 :  0.9216160135867995 1.85467827301114e-11\n",
      "23 :  0.8867413289876822 1.7946972601888134e-11\n",
      "24 :  0.6151751669476653 2.99484912052933e-11\n",
      "25 :  1.115349081867862 0.5218770601246728\n",
      "26 :  0.6072478073228922 1.7794244655779114e-11\n",
      "27 :  0.7022608542010857 1.154250250673524e-11\n",
      "28 :  0.7058461509368499 8.380420206895666e-12\n",
      "29 :  1.1150639396978477 0.011659165403217434\n",
      "currect curriculum:  2\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 0\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 1\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 2\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 3\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 4\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 5\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 6\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 7\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 8\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 9\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 10\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 11\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 12\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 13\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 14\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 15\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 16\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 17\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 18\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 19\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 20\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 21\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 22\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 23\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 24\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 25\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 26\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 27\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 28\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 29\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 30\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 31\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 32\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 33\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 34\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 35\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 36\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 37\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 38\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 39\n",
      "0 :  0.37677874381779475 1.55585087988629e-11\n",
      "1 :  0.7201404175566495 2.0119162384695516e-11\n",
      "2 :  1.115349081867862 0.3566397230927373\n",
      "3 :  1.1150639396978477 0.002691775288268998\n",
      "4 :  1.4756238023867354 1.066576596524793\n",
      "5 :  0.6248641672154918 5.962432681208263e-12\n",
      "6 :  1.3055174419891955 0.6277669365803392\n",
      "7 :  0.7058461509368499 5.936739757475956e-12\n",
      "8 :  1.097205785915321 1.92769051441728e-11\n",
      "9 :  0.8683939133684362 2.11439161545146e-11\n",
      "10 :  0.6151751669476653 2.0583518201173036e-11\n",
      "11 :  0.7022608542010857 7.997224849334498e-12\n",
      "12 :  0.8194501217340076 3.2173656061523776e-11\n",
      "13 :  0.46490663736813076 2.4776852276551962e-11\n",
      "14 :  1.0293603778291072 3.9936212786484085e-06\n",
      "15 :  0.8301311424233973 3.094187329856292e-11\n",
      "16 :  1.7670827665897377 0.8837532787891409\n",
      "17 :  0.6677158110928758 2.0588860222274305e-11\n",
      "18 :  0.6072478073228922 1.075917459626226e-11\n",
      "19 :  1.2037116561025414 0.7609715238315854\n",
      "20 :  0.7082653196380306 1.6866845715956327e-11\n",
      "21 :  1.0726768699150853 4.653589257291711e-06\n",
      "22 :  1.2670405690760163 1.0255233138171747\n",
      "23 :  1.202162290803244 0.1770040501946922\n",
      "24 :  0.7591226471954542 2.559043251671458e-11\n",
      "25 :  0.4771332874629479 1.9586192178790416e-11\n",
      "26 :  0.27260375314835983 7.696892144470117e-11\n",
      "27 :  1.140954722496872 0.6953352437308087\n",
      "28 :  0.43154713802073275 4.6795687406712074e-12\n",
      "29 :  1.1619481483326126 0.021303620220646174\n",
      "currect curriculum:  3\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 0\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 1\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 2\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 3\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 4\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 5\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 6\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 7\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 8\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 9\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 10\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 11\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 12\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 13\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 14\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 15\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 16\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 17\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 18\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 19\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 20\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 21\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 22\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 23\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 24\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 25\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 26\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 27\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 28\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 29\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 30\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 31\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 32\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 33\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 34\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 35\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 36\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 37\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 38\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 39\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 40\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 41\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 42\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 43\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 44\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 45\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 46\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 47\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 48\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 49\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 50\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 51\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 52\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 53\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 54\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 55\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 56\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 57\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 58\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 59\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 60\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 61\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 62\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 63\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 64\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 65\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 66\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 67\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 68\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  0.7777448278875454 1.9222378753922837e-11\n",
      "1 :  0.7356487929473587 3.584179839697475e-11\n",
      "2 :  1.193922700984558 0.3731177820986345\n",
      "3 :  0.9216160135867995 2.5296037911520374e-12\n",
      "4 :  0.2728014378433272 2.6544219351093895e-11\n",
      "5 :  0.37488180020409345 5.305273261674978e-14\n",
      "6 :  0.8157422834224235 7.938566394581424e-12\n",
      "7 :  1.115349081867862 0.01928077951636756\n",
      "8 :  1.0726768699150853 4.282721874068697e-13\n",
      "9 :  0.6064157747389345 2.6604850262568412e-12\n",
      "10 :  0.6537341319417465 2.0944082830404186e-11\n",
      "11 :  0.6677158110928758 1.9080130871369904e-11\n",
      "12 :  1.3055174419891955 0.6225112277242013\n",
      "13 :  0.6903666877369687 2.5129790517690563e-11\n",
      "14 :  0.8683939133684362 1.0385172297351456e-11\n",
      "15 :  0.22786578133172952 6.514733455759635e-12\n",
      "16 :  0.27260375314835983 7.531164663122189e-11\n",
      "17 :  1.1392343260004054 0.009053985601105534\n",
      "18 :  0.7797230435419351 8.36558483194453e-12\n",
      "19 :  0.6151751669476653 1.7788081022651586e-11\n",
      "20 :  0.9502730507106207 1.4696053695319184e-11\n",
      "21 :  1.2186191433333988 0.3958023028144767\n",
      "22 :  0.19150886322222505 1.2529595404294153e-11\n",
      "23 :  0.8867413289876822 9.038672158310722e-12\n",
      "24 :  1.2037116561025414 0.5761971422566132\n",
      "25 :  1.1619481483326126 0.02661983482952598\n",
      "26 :  1.1013110904359564 0.0001655167027376117\n",
      "27 :  1.202162290803244 0.06909237804074322\n",
      "28 :  0.5345394247315198 2.24644625247382e-11\n",
      "29 :  1.1979787282400594 0.7705417212293365\n"
     ]
    }
   ],
   "source": [
    "curriculum_10 = {\n",
    "    \"load_dir\"        : 'instances/curriculum_10',\n",
    "    \"idx_list\"        : list(range(10)),\n",
    "    \"timelimit\"       : 50,\n",
    "    \"reward_type\"     : 'obj'\n",
    "}\n",
    "\n",
    "curriculum_40 = {\n",
    "    \"load_dir\"        : 'instances/curriculum_40',\n",
    "    \"idx_list\"        : list(range(40)),\n",
    "    \"timelimit\"       : 50,\n",
    "    \"reward_type\"     : 'obj'\n",
    "}\n",
    "\n",
    "curriculum_70 = {\n",
    "    \"load_dir\"        : 'instances/curriculum_70',\n",
    "    \"idx_list\"        : list(range(70)),\n",
    "    \"timelimit\"       : 50,\n",
    "    \"reward_type\"     : 'obj'\n",
    "}\n",
    "\n",
    "c = [curriculum_10, curriculum_40,curriculum_70]\n",
    "if __name__ == \"__main__\":\n",
    "    # create env\n",
    "    \n",
    "    var_size = 61\n",
    "    attention_size = 32\n",
    "    k = 16\n",
    "    hidden_size= 64\n",
    "    lr = 3e-4\n",
    "    sigma = 5\n",
    "    gamma = 0.95\n",
    "    \n",
    "    Policy = PN.Policy_Network(var_size = var_size, attention_size = attention_size, k = k, hidden_size = hidden_size, lr = lr)\n",
    "    \n",
    "    for i in range(3):\n",
    "        print('currect curriculum: ',i+1)\n",
    "        env = make_multiple_env(**c[i])\n",
    "\n",
    "        # To record traectories generated from current policy\n",
    "\n",
    "        for e in range(30): \n",
    "\n",
    "            CONSTRAINTS = []  \n",
    "            CANDIDATES = []\n",
    "            ACTS = []\n",
    "            PROBABILITY = []  \n",
    "            REWARDS = []  \n",
    "\n",
    "            s = env.reset()   # samples a random instance every time env.reset() is called\n",
    "            d = False\n",
    "            t = 0\n",
    "            repisode = 0\n",
    "            total_loss = 0\n",
    "\n",
    "            while not d:\n",
    "                #Take a random action\n",
    "                A, b, c0, cuts_a, cuts_b = s\n",
    "                # find attention score\n",
    "                a_b = np.concatenate((A,np.expand_dims(b,-1)),1)\n",
    "                d_e = np.concatenate((cuts_a,np.expand_dims(cuts_b,-1)),1)\n",
    "                total = np.concatenate((a_b, d_e),0)\n",
    "\n",
    "                total = (total - np.mean(total)) / np.std(total)\n",
    "\n",
    "                constraint = total[:len(a_b)]\n",
    "                candidate = total[len(a_b):]\n",
    "\n",
    "                CONSTRAINTS.append(constraint)\n",
    "                CANDIDATES.append(candidate)\n",
    "                attention_score = Policy.compute_attention(constraint, candidate)\n",
    "                prob = Policy.compute_prob(attention_score)\n",
    "\n",
    "                a = np.array([np.argmax(prob)])\n",
    "                ACTS.append(a)\n",
    "\n",
    "                s, r, d, _ = env.step(a)\n",
    "                #print('episode', e, 'step', t, 'reward', r)            \n",
    "                REWARDS.append(r)\n",
    "\n",
    "                t += 1\n",
    "                repisode += r\n",
    "\n",
    "            # TODO:  Use discounted_rewards function to compute \\hat{V}s/\\hat{Q}s  from instant rewards in rews\n",
    "            discounted_r = H.discounted_rewards(REWARDS, gamma)\n",
    "            Q_s = H.evolution_strategies(discounted_r, sigma)\n",
    "\n",
    "            for contraint,candidate,act,q_s in zip(CONSTRAINTS,CANDIDATES,ACTS,Q_s):\n",
    "                loss = Policy.train(contraint,candidate,act,np.array([q_s]))\n",
    "                total_loss += loss\n",
    "            print(e, \": \", repisode, total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "PATH = cwd + '/Policy/curriculum_model'\n",
    "torch.save(Policy, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:16oyiz8b) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b067e5c566d042b3a00b9bf8d1e7d8f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training reward</td><td>▁█</td></tr><tr><td>training reward moving average</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training reward</td><td>0.90482</td></tr><tr><td>training reward moving average</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vibrant-serenity-5168</strong>: <a href=\"https://wandb.ai/orcs4529/finalproject/runs/16oyiz8b\" target=\"_blank\">https://wandb.ai/orcs4529/finalproject/runs/16oyiz8b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221217_194556-16oyiz8b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:16oyiz8b). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bae07316da94d1da91c2029c635fa65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01671237568370998, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leon66/Desktop/Machine Learning/Reinforcement Learning/Final Project/al4263_LeonLi_Project/wandb/run-20221217_194626-zhex3s55</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/orcs4529/finalproject/runs/zhex3s55\" target=\"_blank\">zany-yogurt-5169</a></strong> to <a href=\"https://wandb.ai/orcs4529/finalproject\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training instances, dir instances/train_100_n60_m60 idx 0\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 1\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 2\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 3\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 4\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 5\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 6\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 7\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 8\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 9\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 10\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 11\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 12\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 13\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 14\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 15\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 16\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 17\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 18\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 19\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 20\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 21\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 22\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 23\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 24\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 25\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 26\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 27\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 28\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 29\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 30\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 31\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 32\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 33\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 34\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 35\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 36\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 37\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 38\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 39\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 40\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 41\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 42\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 43\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 44\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 45\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 46\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 47\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 48\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 49\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 50\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 51\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 52\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 53\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 54\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 55\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 56\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 57\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 58\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 59\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 60\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 61\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 62\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 63\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 64\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 65\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 66\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 67\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 68\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 69\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 70\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 71\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 72\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 73\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 74\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 75\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 76\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 77\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 78\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 79\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 80\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 81\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 82\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 83\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 84\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 85\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 86\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 87\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 88\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 89\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 90\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 91\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 92\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 93\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 94\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 95\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 96\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 97\n",
      "loading training instances, dir instances/train_100_n60_m60 idx 98\n",
      "0 :  0.7898175097679996 1.1151923045960856e-11\n",
      "1 :  0.7077630298233544 7.79819650129418e-12\n",
      "2 :  0.5879741335402286 2.403515391576172e-11\n",
      "3 :  0.6072478073228922 1.134562520426959e-11\n",
      "4 :  1.61589945776268 1.71163615664409\n",
      "5 :  0.43154713802073275 4.197149527698086e-12\n",
      "6 :  1.3055174419914692 0.6751061047516947\n",
      "7 :  0.8301311424270352 3.181501922468376e-11\n",
      "8 :  1.1057218683463361 6.235392247461502e-05\n",
      "9 :  1.1979787282400594 0.7589724882353327\n",
      "10 :  1.2186191433333988 0.6209637522756369\n",
      "11 :  0.8867413289876822 1.6152853462404615e-11\n",
      "12 :  0.8157422834224235 1.1487138741140303e-11\n",
      "13 :  0.7058461509368499 5.4281137506784425e-12\n",
      "14 :  0.7082653196380306 1.3564238801755517e-11\n",
      "15 :  0.4184255748755277 2.171934655305981e-11\n",
      "16 :  0.4866434572811613 9.075565250487791e-12\n",
      "17 :  0.964995842100052 3.12476457189454e-11\n",
      "18 :  1.202162290803244 0.0026114669461006377\n",
      "19 :  0.6541767025703393 6.007848735131862e-13\n",
      "20 :  0.8683939133684362 8.568361848396923e-12\n",
      "21 :  0.8194501217340076 4.596678011651762e-11\n",
      "22 :  0.5071256399173762 1.1823864683838974e-11\n",
      "23 :  1.0293603778291072 3.5867991763408643e-11\n",
      "24 :  0.7591226471954542 4.1693781330065865e-11\n",
      "25 :  1.7670827665897377 0.7034385848223221\n",
      "26 :  0.7681320403873997 1.8345644721284782e-11\n",
      "27 :  0.6903666877369687 3.740585785152589e-11\n",
      "28 :  0.7777448278875454 2.9161610688157884e-11\n",
      "29 :  1.0726768699150853 4.4102307790064193e-14\n"
     ]
    }
   ],
   "source": [
    "run=wandb.init(project=\"finalproject\", entity=\"orcs4529\", tags=[\"training-hard\"])\n",
    "\n",
    "### TRAINING\n",
    "\n",
    "# Hard Setup: Use the following environment settings. We will evaluate your agent with the same hard config below:\n",
    "hard_config = {\n",
    "    \"load_dir\"        : 'instances/train_100_n60_m60',\n",
    "    \"idx_list\"        : list(range(99)),\n",
    "    \"timelimit\"       : 50,\n",
    "    \"reward_type\"     : 'obj'\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # create env\n",
    "    \n",
    "    lr = 3e-4\n",
    "    PATH = cwd + '/Policy/curriculum_model'\n",
    "    Policy = torch.load(PATH)\n",
    "    env = make_multiple_env(**hard_config)\n",
    "    sigma = 5\n",
    "    gamma = 0.99\n",
    "    rrecord = []\n",
    "\n",
    "    # To record traectories generated from current policy\n",
    "    \n",
    "    for e in range(30): \n",
    "\n",
    "        CONSTRAINTS = []  \n",
    "        CANDIDATES = []\n",
    "        ACTS = []\n",
    "        PROBABILITY = []  \n",
    "        REWARDS = []  \n",
    "\n",
    "        s = env.reset()   # samples a random instance every time env.reset() is called\n",
    "        d = False\n",
    "        t = 0\n",
    "        repisode = 0\n",
    "        total_loss = 0\n",
    "        while not d:\n",
    "            #Take a random action\n",
    "            A, b, c0, cuts_a, cuts_b = s\n",
    "            # find attention score\n",
    "            a_b = np.concatenate((A,np.expand_dims(b,-1)),1)\n",
    "            d_e = np.concatenate((cuts_a,np.expand_dims(cuts_b,-1)),1)\n",
    "            total = np.concatenate((a_b, d_e),0)\n",
    "\n",
    "            total = (total - np.mean(total)) / np.std(total)\n",
    "            #total / np.linalg.norm(total)\n",
    "            \n",
    "            constraint = total[:len(a_b)]\n",
    "            candidate = total[len(a_b):]\n",
    "\n",
    "            CONSTRAINTS.append(constraint)\n",
    "            CANDIDATES.append(candidate)\n",
    "            attention_score = Policy.compute_attention(constraint, candidate)\n",
    "            prob = Policy.compute_prob(attention_score)\n",
    "            \n",
    "            a = np.array([np.argmax(prob)])\n",
    "            ACTS.append(a)\n",
    "\n",
    "            s, r, d, _ = env.step(a)\n",
    "            #print('episode', e, 'step', t, 'reward', r)            \n",
    "            REWARDS.append(r)\n",
    "\n",
    "            t += 1\n",
    "            repisode += r\n",
    "            \n",
    "        \n",
    "        #Below is for logging training performance\n",
    "        rrecord.append(np.sum(REWARDS))\n",
    "        \n",
    "        # TODO:  Use discounted_rewards function to compute \\hat{V}s/\\hat{Q}s  from instant rewards in rews\n",
    "        discounted_r = H.discounted_rewards(REWARDS, gamma)\n",
    "        Q_s = H.evolution_strategies(discounted_r, sigma)\n",
    "        \n",
    "        for contraint,candidate,act,q_s in zip(CONSTRAINTS,CANDIDATES,ACTS,Q_s):\n",
    "            loss = Policy.train(contraint,candidate,act,np.array([q_s]))\n",
    "            total_loss += loss\n",
    "        print(e, \": \", repisode, total_loss)\n",
    "\n",
    "        fixedWindow=5\n",
    "        movingAverage=0\n",
    "        if len(rrecord) >= fixedWindow:\n",
    "            movingAverage=np.mean(rrecord[len(rrecord)-fixedWindow:len(rrecord)-1])\n",
    "\n",
    "        #wandb logging\n",
    "        wandb.log({ \"training reward\" : rrecord[-1], \"training reward moving average\" : movingAverage})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "PATH = cwd + '/Policy/hard_model'\n",
    "torch.save(Policy, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: 200 Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:zhex3s55) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868a4c2e6a9b40858aedc976f631cfbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.019 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.045392…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training reward</td><td>▃▃▂▂▇▁▆▃▅▅▅▃▃▂▃▁▁▄▅▂▃▃▁▄▃█▃▂▃▄</td></tr><tr><td>training reward moving average</td><td>▁▁▁▁▅▇▆▇█▇███▇▇▆▅▅▅▆▆▇▇▅▆▆▇█▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training reward</td><td>1.07268</td></tr><tr><td>training reward moving average</td><td>1.00083</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">zany-yogurt-5169</strong>: <a href=\"https://wandb.ai/orcs4529/finalproject/runs/zhex3s55\" target=\"_blank\">https://wandb.ai/orcs4529/finalproject/runs/zhex3s55</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221217_194626-zhex3s55/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:zhex3s55). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecdbd9621774c20abbeed6f2ab4ec09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01670797708405492, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/leon66/Desktop/Machine Learning/Reinforcement Learning/Final Project/al4263_LeonLi_Project/wandb/run-20221217_201443-234v8dob</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/orcs4529/finalproject/runs/234v8dob\" target=\"_blank\">breezy-moon-5185</a></strong> to <a href=\"https://wandb.ai/orcs4529/finalproject\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training instances, dir instances/200_instance idx 0\n",
      "loading training instances, dir instances/200_instance idx 1\n",
      "loading training instances, dir instances/200_instance idx 2\n",
      "loading training instances, dir instances/200_instance idx 3\n",
      "loading training instances, dir instances/200_instance idx 4\n",
      "loading training instances, dir instances/200_instance idx 5\n",
      "loading training instances, dir instances/200_instance idx 6\n",
      "loading training instances, dir instances/200_instance idx 7\n",
      "loading training instances, dir instances/200_instance idx 8\n",
      "loading training instances, dir instances/200_instance idx 9\n",
      "loading training instances, dir instances/200_instance idx 10\n",
      "loading training instances, dir instances/200_instance idx 11\n",
      "loading training instances, dir instances/200_instance idx 12\n",
      "loading training instances, dir instances/200_instance idx 13\n",
      "loading training instances, dir instances/200_instance idx 14\n",
      "loading training instances, dir instances/200_instance idx 15\n",
      "loading training instances, dir instances/200_instance idx 16\n",
      "loading training instances, dir instances/200_instance idx 17\n",
      "loading training instances, dir instances/200_instance idx 18\n",
      "loading training instances, dir instances/200_instance idx 19\n",
      "loading training instances, dir instances/200_instance idx 20\n",
      "loading training instances, dir instances/200_instance idx 21\n",
      "loading training instances, dir instances/200_instance idx 22\n",
      "loading training instances, dir instances/200_instance idx 23\n",
      "loading training instances, dir instances/200_instance idx 24\n",
      "loading training instances, dir instances/200_instance idx 25\n",
      "loading training instances, dir instances/200_instance idx 26\n",
      "loading training instances, dir instances/200_instance idx 27\n",
      "loading training instances, dir instances/200_instance idx 28\n",
      "loading training instances, dir instances/200_instance idx 29\n",
      "loading training instances, dir instances/200_instance idx 30\n",
      "loading training instances, dir instances/200_instance idx 31\n",
      "loading training instances, dir instances/200_instance idx 32\n",
      "loading training instances, dir instances/200_instance idx 33\n",
      "loading training instances, dir instances/200_instance idx 34\n",
      "loading training instances, dir instances/200_instance idx 35\n",
      "loading training instances, dir instances/200_instance idx 36\n",
      "loading training instances, dir instances/200_instance idx 37\n",
      "loading training instances, dir instances/200_instance idx 38\n",
      "loading training instances, dir instances/200_instance idx 39\n",
      "loading training instances, dir instances/200_instance idx 40\n",
      "loading training instances, dir instances/200_instance idx 41\n",
      "loading training instances, dir instances/200_instance idx 42\n",
      "loading training instances, dir instances/200_instance idx 43\n",
      "loading training instances, dir instances/200_instance idx 44\n",
      "loading training instances, dir instances/200_instance idx 45\n",
      "loading training instances, dir instances/200_instance idx 46\n",
      "loading training instances, dir instances/200_instance idx 47\n",
      "loading training instances, dir instances/200_instance idx 48\n",
      "loading training instances, dir instances/200_instance idx 49\n",
      "loading training instances, dir instances/200_instance idx 50\n",
      "loading training instances, dir instances/200_instance idx 51\n",
      "loading training instances, dir instances/200_instance idx 52\n",
      "loading training instances, dir instances/200_instance idx 53\n",
      "loading training instances, dir instances/200_instance idx 54\n",
      "loading training instances, dir instances/200_instance idx 55\n",
      "loading training instances, dir instances/200_instance idx 56\n",
      "loading training instances, dir instances/200_instance idx 57\n",
      "loading training instances, dir instances/200_instance idx 58\n",
      "loading training instances, dir instances/200_instance idx 59\n",
      "loading training instances, dir instances/200_instance idx 60\n",
      "loading training instances, dir instances/200_instance idx 61\n",
      "loading training instances, dir instances/200_instance idx 62\n",
      "loading training instances, dir instances/200_instance idx 63\n",
      "loading training instances, dir instances/200_instance idx 64\n",
      "loading training instances, dir instances/200_instance idx 65\n",
      "loading training instances, dir instances/200_instance idx 66\n",
      "loading training instances, dir instances/200_instance idx 67\n",
      "loading training instances, dir instances/200_instance idx 68\n",
      "loading training instances, dir instances/200_instance idx 69\n",
      "loading training instances, dir instances/200_instance idx 70\n",
      "loading training instances, dir instances/200_instance idx 71\n",
      "loading training instances, dir instances/200_instance idx 72\n",
      "loading training instances, dir instances/200_instance idx 73\n",
      "loading training instances, dir instances/200_instance idx 74\n",
      "loading training instances, dir instances/200_instance idx 75\n",
      "loading training instances, dir instances/200_instance idx 76\n",
      "loading training instances, dir instances/200_instance idx 77\n",
      "loading training instances, dir instances/200_instance idx 78\n",
      "loading training instances, dir instances/200_instance idx 79\n",
      "loading training instances, dir instances/200_instance idx 80\n",
      "loading training instances, dir instances/200_instance idx 81\n",
      "loading training instances, dir instances/200_instance idx 82\n",
      "loading training instances, dir instances/200_instance idx 83\n",
      "loading training instances, dir instances/200_instance idx 84\n",
      "loading training instances, dir instances/200_instance idx 85\n",
      "loading training instances, dir instances/200_instance idx 86\n",
      "loading training instances, dir instances/200_instance idx 87\n",
      "loading training instances, dir instances/200_instance idx 88\n",
      "loading training instances, dir instances/200_instance idx 89\n",
      "loading training instances, dir instances/200_instance idx 90\n",
      "loading training instances, dir instances/200_instance idx 91\n",
      "loading training instances, dir instances/200_instance idx 92\n",
      "loading training instances, dir instances/200_instance idx 93\n",
      "loading training instances, dir instances/200_instance idx 94\n",
      "loading training instances, dir instances/200_instance idx 95\n",
      "loading training instances, dir instances/200_instance idx 96\n",
      "loading training instances, dir instances/200_instance idx 97\n",
      "loading training instances, dir instances/200_instance idx 98\n",
      "loading training instances, dir instances/200_instance idx 99\n",
      "loading training instances, dir instances/200_instance idx 100\n",
      "loading training instances, dir instances/200_instance idx 101\n",
      "loading training instances, dir instances/200_instance idx 102\n",
      "loading training instances, dir instances/200_instance idx 103\n",
      "loading training instances, dir instances/200_instance idx 104\n",
      "loading training instances, dir instances/200_instance idx 105\n",
      "loading training instances, dir instances/200_instance idx 106\n",
      "loading training instances, dir instances/200_instance idx 107\n",
      "loading training instances, dir instances/200_instance idx 108\n",
      "loading training instances, dir instances/200_instance idx 109\n",
      "loading training instances, dir instances/200_instance idx 110\n",
      "loading training instances, dir instances/200_instance idx 111\n",
      "loading training instances, dir instances/200_instance idx 112\n",
      "loading training instances, dir instances/200_instance idx 113\n",
      "loading training instances, dir instances/200_instance idx 114\n",
      "loading training instances, dir instances/200_instance idx 115\n",
      "loading training instances, dir instances/200_instance idx 116\n",
      "loading training instances, dir instances/200_instance idx 117\n",
      "loading training instances, dir instances/200_instance idx 118\n",
      "loading training instances, dir instances/200_instance idx 119\n",
      "loading training instances, dir instances/200_instance idx 120\n",
      "loading training instances, dir instances/200_instance idx 121\n",
      "loading training instances, dir instances/200_instance idx 122\n",
      "loading training instances, dir instances/200_instance idx 123\n",
      "loading training instances, dir instances/200_instance idx 124\n",
      "loading training instances, dir instances/200_instance idx 125\n",
      "loading training instances, dir instances/200_instance idx 126\n",
      "loading training instances, dir instances/200_instance idx 127\n",
      "loading training instances, dir instances/200_instance idx 128\n",
      "loading training instances, dir instances/200_instance idx 129\n",
      "loading training instances, dir instances/200_instance idx 130\n",
      "loading training instances, dir instances/200_instance idx 131\n",
      "loading training instances, dir instances/200_instance idx 132\n",
      "loading training instances, dir instances/200_instance idx 133\n",
      "loading training instances, dir instances/200_instance idx 134\n",
      "loading training instances, dir instances/200_instance idx 135\n",
      "loading training instances, dir instances/200_instance idx 136\n",
      "loading training instances, dir instances/200_instance idx 137\n",
      "loading training instances, dir instances/200_instance idx 138\n",
      "loading training instances, dir instances/200_instance idx 139\n",
      "loading training instances, dir instances/200_instance idx 140\n",
      "loading training instances, dir instances/200_instance idx 141\n",
      "loading training instances, dir instances/200_instance idx 142\n",
      "loading training instances, dir instances/200_instance idx 143\n",
      "loading training instances, dir instances/200_instance idx 144\n",
      "loading training instances, dir instances/200_instance idx 145\n",
      "loading training instances, dir instances/200_instance idx 146\n",
      "loading training instances, dir instances/200_instance idx 147\n",
      "loading training instances, dir instances/200_instance idx 148\n",
      "loading training instances, dir instances/200_instance idx 149\n",
      "loading training instances, dir instances/200_instance idx 150\n",
      "loading training instances, dir instances/200_instance idx 151\n",
      "loading training instances, dir instances/200_instance idx 152\n",
      "loading training instances, dir instances/200_instance idx 153\n",
      "loading training instances, dir instances/200_instance idx 154\n",
      "loading training instances, dir instances/200_instance idx 155\n",
      "loading training instances, dir instances/200_instance idx 156\n",
      "loading training instances, dir instances/200_instance idx 157\n",
      "loading training instances, dir instances/200_instance idx 158\n",
      "loading training instances, dir instances/200_instance idx 159\n",
      "loading training instances, dir instances/200_instance idx 160\n",
      "loading training instances, dir instances/200_instance idx 161\n",
      "loading training instances, dir instances/200_instance idx 162\n",
      "loading training instances, dir instances/200_instance idx 163\n",
      "loading training instances, dir instances/200_instance idx 164\n",
      "loading training instances, dir instances/200_instance idx 165\n",
      "loading training instances, dir instances/200_instance idx 166\n",
      "loading training instances, dir instances/200_instance idx 167\n",
      "loading training instances, dir instances/200_instance idx 168\n",
      "loading training instances, dir instances/200_instance idx 169\n",
      "loading training instances, dir instances/200_instance idx 170\n",
      "loading training instances, dir instances/200_instance idx 171\n",
      "loading training instances, dir instances/200_instance idx 172\n",
      "loading training instances, dir instances/200_instance idx 173\n",
      "loading training instances, dir instances/200_instance idx 174\n",
      "loading training instances, dir instances/200_instance idx 175\n",
      "loading training instances, dir instances/200_instance idx 176\n",
      "loading training instances, dir instances/200_instance idx 177\n",
      "loading training instances, dir instances/200_instance idx 178\n",
      "loading training instances, dir instances/200_instance idx 179\n",
      "loading training instances, dir instances/200_instance idx 180\n",
      "loading training instances, dir instances/200_instance idx 181\n",
      "loading training instances, dir instances/200_instance idx 182\n",
      "loading training instances, dir instances/200_instance idx 183\n",
      "loading training instances, dir instances/200_instance idx 184\n",
      "loading training instances, dir instances/200_instance idx 185\n",
      "loading training instances, dir instances/200_instance idx 186\n",
      "loading training instances, dir instances/200_instance idx 187\n",
      "loading training instances, dir instances/200_instance idx 188\n",
      "loading training instances, dir instances/200_instance idx 189\n",
      "loading training instances, dir instances/200_instance idx 190\n",
      "loading training instances, dir instances/200_instance idx 191\n",
      "loading training instances, dir instances/200_instance idx 192\n",
      "loading training instances, dir instances/200_instance idx 193\n",
      "loading training instances, dir instances/200_instance idx 194\n",
      "loading training instances, dir instances/200_instance idx 195\n",
      "loading training instances, dir instances/200_instance idx 196\n",
      "loading training instances, dir instances/200_instance idx 197\n",
      "loading training instances, dir instances/200_instance idx 198\n",
      "loading training instances, dir instances/200_instance idx 199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  0.5162786186374433 7.485547466475e-12\n",
      "1 :  1.001470740719924 1.065125953462011e-11\n",
      "2 :  0.8364482100646455 3.58470454708127e-11\n",
      "3 :  0.9014635093624292 3.727691075888632e-11\n",
      "4 :  0.8925334688728981 5.1760232964848814e-11\n",
      "5 :  1.2037116561025414 0.7290326998490219\n",
      "6 :  1.0741382596181666 0.00012864584862755583\n",
      "7 :  0.9939785146214035 1.4373194774636387e-11\n",
      "8 :  0.6009325061550044 3.710366591310265e-11\n",
      "9 :  0.5212616680737483 1.6190230429421627e-11\n",
      "10 :  0.6276721296799224 7.76603247338741e-11\n",
      "11 :  0.5094071355547385 3.503106257659047e-11\n",
      "12 :  0.2961509774725073 2.9568693249457325e-12\n",
      "13 :  0.4994096325872306 3.5804823068894446e-11\n",
      "14 :  0.3593805646942201 3.524202513938324e-11\n",
      "15 :  0.9351388868612958 1.535153711830229e-11\n",
      "16 :  1.3563837944557235 1.2208617960283001\n",
      "17 :  1.0245019860603861 0.0001209560289006004\n",
      "18 :  0.8967601663971436 1.476503758373959e-11\n",
      "19 :  1.3792470687105833 1.2280564537005034\n",
      "20 :  0.12642602396863367 4.692451398273828e-13\n",
      "21 :  0.5817997123542682 1.641257714164344e-11\n",
      "22 :  0.8788479522868329 3.140632424016974e-11\n",
      "23 :  1.0849698719846401 2.4931331305068666e-11\n",
      "24 :  0.42860485797291403 4.1023407032624145e-12\n",
      "25 :  0.8796586335888605 1.8262657273179834e-11\n",
      "26 :  0.42417057397028657 3.1033951123550845e-11\n",
      "27 :  1.1044604532280573 0.6906437012982347\n",
      "28 :  1.1132755920079944 4.403537538950897e-12\n",
      "29 :  0.6556782175653098 2.6034923980511145e-11\n"
     ]
    }
   ],
   "source": [
    "## Hard Mode\n",
    "run=wandb.init(project=\"finalproject\", entity=\"orcs4529\", tags=[\"training-hard\"])\n",
    "\n",
    "### TRAINING\n",
    "\n",
    "# Hard Setup: Use the following environment settings. We will evaluate your agent with the same hard config below:\n",
    "Hhard_config = {\n",
    "    \"load_dir\"        : 'instances/200_instance',\n",
    "    \"idx_list\"        : list(range(200)),\n",
    "    \"timelimit\"       : 50,\n",
    "    \"reward_type\"     : 'obj'\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # create env\n",
    "    \n",
    "    lr = 3e-4\n",
    "    PATH = cwd + '/Policy/curriculum_model'\n",
    "    Policy = torch.load(PATH)\n",
    "    env = make_multiple_env(**Hhard_config)\n",
    "    sigma = 5\n",
    "    gamma = 0.99\n",
    "    rrecord = []\n",
    "\n",
    "    # To record traectories generated from current policy\n",
    "    \n",
    "    for e in range(30): \n",
    "\n",
    "        CONSTRAINTS = []  \n",
    "        CANDIDATES = []\n",
    "        ACTS = []\n",
    "        PROBABILITY = []  \n",
    "        REWARDS = []  \n",
    "\n",
    "        s = env.reset()   # samples a random instance every time env.reset() is called\n",
    "        d = False\n",
    "        t = 0\n",
    "        repisode = 0\n",
    "        total_loss = 0\n",
    "        while not d:\n",
    "            #Take a random action\n",
    "            A, b, c0, cuts_a, cuts_b = s\n",
    "            # find attention score\n",
    "            a_b = np.concatenate((A,np.expand_dims(b,-1)),1)\n",
    "            d_e = np.concatenate((cuts_a,np.expand_dims(cuts_b,-1)),1)\n",
    "            total = np.concatenate((a_b, d_e),0)\n",
    "\n",
    "            total = (total - np.mean(total)) / np.std(total)\n",
    "            #total / np.linalg.norm(total)\n",
    "            \n",
    "            constraint = total[:len(a_b)]\n",
    "            candidate = total[len(a_b):]\n",
    "\n",
    "            CONSTRAINTS.append(constraint)\n",
    "            CANDIDATES.append(candidate)\n",
    "            attention_score = Policy.compute_attention(constraint, candidate)\n",
    "            prob = Policy.compute_prob(attention_score)\n",
    "            \n",
    "            a = np.array([np.argmax(prob)])\n",
    "            ACTS.append(a)\n",
    "\n",
    "            s, r, d, _ = env.step(a)\n",
    "            #print('episode', e, 'step', t, 'reward', r)            \n",
    "            REWARDS.append(r)\n",
    "\n",
    "            t += 1\n",
    "            repisode += r\n",
    "            \n",
    "        \n",
    "        #Below is for logging training performance\n",
    "        rrecord.append(np.sum(REWARDS))\n",
    "        \n",
    "        # TODO:  Use discounted_rewards function to compute \\hat{V}s/\\hat{Q}s  from instant rewards in rews\n",
    "        discounted_r = H.discounted_rewards(REWARDS, gamma)\n",
    "        Q_s = H.evolution_strategies(discounted_r, sigma)\n",
    "        \n",
    "        for contraint,candidate,act,q_s in zip(CONSTRAINTS,CANDIDATES,ACTS,Q_s):\n",
    "            loss = Policy.train(contraint,candidate,act,np.array([q_s]))\n",
    "            total_loss += loss\n",
    "        print(e, \": \", repisode, total_loss)\n",
    "\n",
    "        fixedWindow=5\n",
    "        movingAverage=0\n",
    "        if len(rrecord) >= fixedWindow:\n",
    "            movingAverage=np.mean(rrecord[len(rrecord)-fixedWindow:len(rrecord)-1])\n",
    "\n",
    "        #wandb logging\n",
    "        wandb.log({ \"training reward\" : rrecord[-1], \"training reward moving average\" : movingAverage})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training instances, dir instances/randomip_n60_m60 idx 0\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 1\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 2\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 3\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 4\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 5\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 6\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 7\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 8\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 9\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 10\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 11\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 12\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 13\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 14\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 15\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 16\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 17\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 18\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 19\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 20\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 21\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 22\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 23\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 24\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 25\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 26\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 27\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 28\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 29\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 30\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 31\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 32\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 33\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 34\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 35\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 36\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 37\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 38\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 39\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 40\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 41\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 42\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 43\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 44\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 45\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 46\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 47\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 48\n",
      "loading training instances, dir instances/randomip_n60_m60 idx 49\n",
      "step 1 reward 0.7022608541801674 action space size 60\n",
      "step 2 reward 1.3642420526593924e-12 action space size 60\n",
      "step 3 reward 4.547473508864641e-13 action space size 62\n",
      "step 4 reward 0.0 action space size 63\n",
      "step 5 reward 4.547473508864641e-13 action space size 63\n",
      "step 6 reward 4.547473508864641e-13 action space size 65\n",
      "step 7 reward 4.547473508864641e-13 action space size 66\n",
      "step 8 reward 9.094947017729282e-13 action space size 64\n",
      "step 9 reward 9.094947017729282e-13 action space size 68\n",
      "step 10 reward 9.094947017729282e-13 action space size 68\n",
      "step 11 reward 4.547473508864641e-13 action space size 67\n",
      "step 12 reward 0.0 action space size 70\n",
      "step 13 reward 4.547473508864641e-13 action space size 71\n",
      "step 14 reward 4.547473508864641e-13 action space size 70\n",
      "step 15 reward 4.547473508864641e-13 action space size 74\n",
      "step 16 reward 9.094947017729282e-13 action space size 73\n",
      "step 17 reward 4.547473508864641e-13 action space size 76\n",
      "step 18 reward 0.0 action space size 77\n",
      "step 19 reward 4.547473508864641e-13 action space size 79\n",
      "step 20 reward 4.547473508864641e-13 action space size 79\n",
      "step 21 reward 4.547473508864641e-13 action space size 81\n",
      "step 22 reward 0.0 action space size 82\n",
      "step 23 reward 0.0 action space size 82\n",
      "step 24 reward 4.547473508864641e-13 action space size 81\n",
      "step 25 reward 4.547473508864641e-13 action space size 82\n",
      "step 26 reward 9.094947017729282e-13 action space size 86\n",
      "step 27 reward 4.547473508864641e-13 action space size 87\n",
      "step 28 reward 4.547473508864641e-13 action space size 86\n",
      "step 29 reward 4.547473508864641e-13 action space size 86\n",
      "step 30 reward 4.547473508864641e-13 action space size 83\n",
      "step 31 reward 4.547473508864641e-13 action space size 88\n",
      "step 32 reward 0.0 action space size 92\n",
      "step 33 reward 4.547473508864641e-13 action space size 92\n",
      "step 34 reward 4.547473508864641e-13 action space size 94\n",
      "step 35 reward 0.0 action space size 91\n",
      "step 36 reward 4.547473508864641e-13 action space size 94\n",
      "step 37 reward 4.547473508864641e-13 action space size 97\n",
      "step 38 reward 4.547473508864641e-13 action space size 97\n",
      "step 39 reward 4.547473508864641e-13 action space size 99\n",
      "step 40 reward 4.547473508864641e-13 action space size 99\n",
      "step 41 reward 0.0 action space size 99\n",
      "step 42 reward 0.0 action space size 102\n",
      "step 43 reward 9.094947017729282e-13 action space size 103\n",
      "step 44 reward 4.547473508864641e-13 action space size 100\n",
      "step 45 reward 0.0 action space size 103\n",
      "step 46 reward 9.094947017729282e-13 action space size 103\n",
      "step 47 reward 9.094947017729282e-13 action space size 103\n",
      "step 48 reward 0.0 action space size 106\n",
      "step 49 reward 0.0 action space size 106\n",
      "step 50 reward 0.0 action space size 109\n",
      "total episode reward:  0.7022608542010857\n"
     ]
    }
   ],
   "source": [
    "custom_config = {\n",
    "    \"load_dir\"        : 'instances/randomip_n60_m60',   # this is the location of the randomly generated instances (you may specify a different directory)\n",
    "    \"idx_list\"        : list(range(50)),                # take the first 20 instances from the directory\n",
    "    \"timelimit\"       : 50,                             # the maximum horizon length is 50\n",
    "    \"reward_type\"     : 'obj'                           # DO NOT CHANGE reward_type\n",
    "}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # create env\n",
    "    \n",
    "    PATH = cwd + '/Policy/easy_model'\n",
    "    #PATH = cwd + '/Policy/hard_model'\n",
    "    Policy = torch.load(PATH)\n",
    "    env = make_multiple_env(**custom_config)\n",
    "\n",
    "    # To record traectories generated from current policy\n",
    "    \n",
    "    s = env.reset()   # samples a random instance every time env.reset() is called\n",
    "    d = False\n",
    "    t = 0\n",
    "    repisode = 0\n",
    "    while not d:\n",
    "        #Take a random action\n",
    "        A, b, c0, cuts_a, cuts_b = s\n",
    "        # find attention score\n",
    "        a_b = np.concatenate((A,np.expand_dims(b,-1)),1)\n",
    "        d_e = np.concatenate((cuts_a,np.expand_dims(cuts_b,-1)),1)\n",
    "        total = np.concatenate((a_b, d_e),0)\n",
    "\n",
    "        total = (total - np.mean(total)) / np.std(total)\n",
    "        #total / np.linalg.norm(total)\n",
    "\n",
    "        constraint = total[:len(a_b)]\n",
    "        candidate = total[len(a_b):]\n",
    "\n",
    "        attention_score = Policy.compute_attention(constraint, candidate)\n",
    "        prob = Policy.compute_prob(attention_score)\n",
    "        a = np.array([np.argmax(prob)])\n",
    "\n",
    "        s, r, d, _ = env.step(a)\n",
    "        t += 1\n",
    "        print('step', t, 'reward', r, 'action space size', s[-1].size)\n",
    "        repisode += r\n",
    "\n",
    "    #Below is for logging training performance\n",
    "    rrecord.append(repisode)\n",
    "\n",
    "    print('total episode reward: ', repisode)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
